---
title: "Using a Certain Generative Pre-trained Transformer to Code NSF Grants"
# description: ""
author: Justin Dollman
date: 05-28-2024
categories: [ChatGPT, coding, NSF]
image: grant_writing.webp
draft: true
---


The original version of this post was going to demonstrate a fully scaled coding endeavor of tens of thousands of documents. Unfortunately for the world (mostly me, though) OpenAI's batch processing is still working out some glitches that prevent (link to forthcoming document)

https://docs.google.com/document/d/1GAKfoEW-7FIF5wyN1p_ag72vjUPdyZiI/edit
https://academic.oup.com/rev/article/32/2/348/6972169

Outline for forthcoming document (which you should post!) -- Basically, the plan is as follows 

1. Carve up each NSF grant abstract into smaller parts (✅, easy regex solution)
  * Should increase performance of downstream coding (FN. Though this is an empirical question. Part of the reason I'm going on this circuitous route is to see if it's true!)
  * Saves tokens. Immediately it costs more time and tokens, but 
  * 
2. Send a sample of those to ChatGPT to code for the *presence* of broader impacts (❌), this is where it would be nice if I could batch
3. Using the now labelled data, build a classifier (✅, using a subsample...)
4. Generate predicted probabilities for which segment of the NSF abstract contains a broader impact.
  4a. The goal is that one of its n segments has a much higher probability than the rest
  4b. 
5. Send each grant's (probably) BI-containing segment to be coded

So, [separating my concerns](), this post will concern only the prompt-engineering considerations for getting ChatGPT to accurately code unstructured text along two somewhat subtle dimensions. The next post will implement 

What are Broader Impacts?
https://new.nsf.gov/funding/learn/broader-impacts

'Coding' unstructured text into nice quantitative features is a time-consuming, mentally-draining, and eventually hellish task. Recently, tried this for a task that human^[It's wild that 'human' is going to become used more and more as a prepositive adjective in front of nouns we .... C'est le siècle le plus important] research assistants had done a poor job at. Sure enough, both ChatGPT (4) and Claude (Opus?) did pretty bad jobs. Google's Gemini didn't even try.

A while back I was part of a project in which the principal investigator was looking at the broader impacts of NSF grants. A prior research assistant had manually coded 400 **project outcome reports**^[] along two dimensions: are the project's beneficiaries `{advantaged, universal, disadvantaged}` and is the relationship between the core activity of the grant and the beneficiaries `{inherent, direct, or indirect}`. I refer you [the resulting publication]() for elaboration on the whys and wherefores of this coding. By the time I was brought onto the project, the task was to figure out if certain types of broader impact strategies were associated with more or fewer publications. Given the complexities of the models I wanted to run (zero-inflated this-and-that, controlling for various institutional factors), the N = 400 sample was pretty meager. 

My first foray into working with the API.

* How similar are API responses to 'manual' responses?

* Structure of a POR

Download grants here: https://www.nsf.gov/awardsearch/download.jsp

Keyword extraction
Useful for (at least) three reasons
Let the PI check the behavior of the classifier quickly
Give the model 'time to think'
Have information to do more in-depth analyses later

key values to get out
description of broader impact (one or two English sentences)
beneficiaries
relationship between project and beneficiaries (training, etc.)
immediacy_code
inclusion_code

What about first using it to build a classifier

# Appendices

## A1: Broader Impact Classifier

## A2: Results of Text-Length Experiment

RQ: How much does irrelevant text degrade the (coding/keyword) capabilities of of ChatGPT?

If you could separate the abstract or project out report 'at the joints, you could send each part to ChatGPT to label it as involving a broader impact or not. Then, with that labelled data you could build a classifier. In a second go through, you'd only send the part about the broader impact to ChatGPT for the coding. This would ultimately save you a lot of tokens (because you only send a relatively small sample to ChatGPT) and likely increase performance (recency/first-thing bias is even worse for LLMs than for humans)